{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:02.694120700Z",
     "start_time": "2026-02-16T08:44:02.444370800Z"
    }
   },
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.8\n",
      "numpy version: 2.4.2\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.10.0\n",
      "tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:02.907262200Z",
     "start_time": "2026-02-16T08:44:02.748772100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#####################################\n",
    "# Chapter 2\n",
    "#####################################\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Chapter 3\n",
    "#####################################\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Chapter 4\n",
    "#####################################\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed-forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest logits value\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx\n",
    "max_length = 256"
   ],
   "id": "44cbceffd9a2d0ea",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:05.506907200Z",
     "start_time": "2026-02-16T08:44:02.965982700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": max_length, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();"
   ],
   "id": "955e13931b8088fa",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:07.399737400Z",
     "start_time": "2026-02-16T08:44:05.607315800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "4a7bc6812c8384d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:07.505963200Z",
     "start_time": "2026-02-16T08:44:07.438768800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ],
   "id": "9dbb1f988ecff726",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:08.243586400Z",
     "start_time": "2026-02-16T08:44:07.541102700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ],
   "id": "6aa5400fd3d97991",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:08.509619100Z",
     "start_time": "2026-02-16T08:44:08.311627800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ],
   "id": "f60460ea7f2e6333",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:08.580052700Z",
     "start_time": "2026-02-16T08:44:08.536951300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ],
   "id": "fde74bc2763f098",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:08.665237800Z",
     "start_time": "2026-02-16T08:44:08.590027400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ],
   "id": "df2f0d5c0f40920c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:08.758470200Z",
     "start_time": "2026-02-16T08:44:08.678341600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ],
   "id": "35aed2272f9a429d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:08.805152200Z",
     "start_time": "2026-02-16T08:44:08.762289800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ],
   "id": "3c58ee8eede0b420",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:08.871727800Z",
     "start_time": "2026-02-16T08:44:08.812168100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cross-entropy loss (instead of maximising the mean of -10.7940 to 0, it's minimising it from 10.7940 to 0)\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ],
   "id": "e2b7480af352a7d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:08.924388600Z",
     "start_time": "2026-02-16T08:44:08.882896400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ],
   "id": "b6d0bbfb635007a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:08.963702800Z",
     "start_time": "2026-02-16T08:44:08.929551100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ],
   "id": "47ae222bcfbb6e27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:09.011971Z",
     "start_time": "2026-02-16T08:44:08.976103800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ],
   "id": "92f814ed68c00c64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:09.054368900Z",
     "start_time": "2026-02-16T08:44:09.017980800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ],
   "id": "bca5a29ab0cc5336",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:09.074580600Z",
     "start_time": "2026-02-16T08:44:09.061598900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "if not os.path.exists(file_path):\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    text_data = response.text\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "\n",
    "# The book originally used the following code below\n",
    "# However, urllib uses older protocol settings that\n",
    "# can cause problems for some readers using a VPN.\n",
    "# The `requests` version above is more robust\n",
    "# in that regard.\n",
    "\n",
    "\n",
    "# import os\n",
    "# import urllib.request\n",
    "\n",
    "# file_path = \"the-verdict.txt\"\n",
    "# url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         text_data = response.read().decode('utf-8')\n",
    "#     with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "#         file.write(text_data)\n",
    "# else:\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         text_data = file.read()\n",
    "\n"
   ],
   "id": "dc9e73e12ae4ae06",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:09.127995300Z",
     "start_time": "2026-02-16T08:44:09.077873600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First 99 characters\n",
    "print(text_data[:99])"
   ],
   "id": "efdbc63ff7fef1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:09.163533800Z",
     "start_time": "2026-02-16T08:44:09.133061700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Last 99 characters\n",
    "print(text_data[-99:])"
   ],
   "id": "7a709b2c42347a79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:09.251141900Z",
     "start_time": "2026-02-16T08:44:09.173566400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ],
   "id": "1b13fb13e58b4ba8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:44:09.307021100Z",
     "start_time": "2026-02-16T08:44:09.272701400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ],
   "id": "de0fb3e9d155e6b6",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:45:15.445561100Z",
     "start_time": "2026-02-16T08:45:15.301043600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ],
   "id": "ca8504e60b7682bc",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:45:26.726325300Z",
     "start_time": "2026-02-16T08:45:26.405072300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ],
   "id": "507fd87997fe85d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:46:10.337094100Z",
     "start_time": "2026-02-16T08:46:09.319962400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ],
   "id": "f5b5772e500274f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:47:03.761594900Z",
     "start_time": "2026-02-16T08:47:03.567103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ],
   "id": "4002ebf521132ddd",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:47:32.551951600Z",
     "start_time": "2026-02-16T08:47:22.704193300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "id": "974e91f5194263de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n",
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T08:50:19.967634600Z",
     "start_time": "2026-02-16T08:50:19.476029900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ],
   "id": "8b3556ff277d8e72",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T09:00:56.788341100Z",
     "start_time": "2026-02-16T08:53:45.952707400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ],
   "id": "65afd60092485ec0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Training completed in 7.17 minutes.\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T09:08:10.055073600Z",
     "start_time": "2026-02-16T09:08:08.352373400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "id": "94d49274e07d348",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T09:07:12.002882600Z",
     "start_time": "2026-02-16T09:07:09.558832400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# NEW: use CPU here as inference is cheap with\n",
    "# this model and to ensure readers get same results in the\n",
    "# remaining sections of this book\n",
    "inference_device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(inference_device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "fd126f8802ae717d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T09:07:24.757220400Z",
     "start_time": "2026-02-16T09:07:24.455167400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ],
   "id": "be92de6727b13d31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T09:08:48.736982800Z",
     "start_time": "2026-02-16T09:08:48.302751900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ],
   "id": "f6213038241646ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T09:08:55.202234700Z",
     "start_time": "2026-02-16T09:08:54.648283100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ],
   "id": "772e00205723c9b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dce316b567e7ca03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
